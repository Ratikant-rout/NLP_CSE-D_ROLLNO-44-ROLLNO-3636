{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM4Ry888DJSqdFnImhG9QB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ratikant-rout/NLP_CSE-D_ROLLNO-46-ROLLNO-41/blob/main/NLP_CLASS_2_PROJECT_WORDS_EXTRACTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVtIFX-qjXWl",
        "outputId": "afc8c4a2-51d6-45c3-e6f1-c73dc7c62fb7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF for extracting text from PDFs\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBLrH1gTjXZ0",
        "outputId": "f1ecaf2f-81d9-47f2-898c-30e7fe6c646c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    doc = fitz.open(pdf_file)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Path to the folder containing your PDF files\n",
        "pdf_folder_path = '/content/IEEE_FOLDER'  # Adjust this to your folder path\n",
        "\n",
        "# List of PDF files in the folder\n",
        "pdf_files = [f for f in os.listdir(pdf_folder_path) if f.endswith('.pdf')]\n",
        "\n",
        "# Initialize a list to store the document texts\n",
        "documents = []\n",
        "\n",
        "# Loop through each PDF file and extract its text\n",
        "for pdf_file in pdf_files:\n",
        "    document_path = os.path.join(pdf_folder_path, pdf_file)\n",
        "    document_text = extract_text_from_pdf(document_path)\n",
        "    documents.append(document_text)\n",
        "\n",
        "# Check how many documents are loaded\n",
        "print(f\"Loaded {len(documents)} documents.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi4UwnJUnu85",
        "outputId": "5c6a2f93-006a-4f38-867f-ecd564251c7d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    words = word_tokenize(text)  # Tokenize the text\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    return words\n",
        "\n",
        "# Preprocess all documents\n",
        "cleaned_documents = [preprocess_text(doc) for doc in documents]\n",
        "\n",
        "# Show a preview of the cleaned text (first 20 words of the first document)\n",
        "print(\"Cleaned Document Preview:\")\n",
        "print(cleaned_documents[0][:20])  # Preview the first 20 words of the first document\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQr9-KsyoDzB",
        "outputId": "6cda35c2-e117-4517-ce88-f12fc96f5714"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Document Preview:\n",
            "['proceedings', 'machine', 'learning', 'research', 'n', 'machine', 'learning', 'healthcare', 'upstage', 'unsupervised', 'context', 'augmentation', 'utterance', 'classication', 'patientprovider', 'communication', 'june', 'min', 'veronica', 'perezrosas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    words = word_tokenize(text)  # Tokenize the text\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    return words\n",
        "\n",
        "# Preprocess all documents\n",
        "cleaned_documents = [preprocess_text(doc) for doc in documents]\n",
        "\n",
        "# Show a preview of the cleaned text (first 20 words of the first document)\n",
        "print(\"Cleaned Document Preview:\")\n",
        "print(cleaned_documents[0][:20])  # Preview the first 20 words of the first document\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQ8XHW2pw6u",
        "outputId": "d6b3ad15-c9a9-4e6b-a256-3408398c9a1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Document Preview:\n",
            "['proceedings', 'machine', 'learning', 'research', 'n', 'machine', 'learning', 'healthcare', 'upstage', 'unsupervised', 'context', 'augmentation', 'utterance', 'classication', 'patientprovider', 'communication', 'june', 'min', 'veronica', 'perezrosas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the cleaned documents back to string format for TF-IDF\n",
        "documents_str = [' '.join(doc) for doc in cleaned_documents]\n",
        "\n",
        "# Apply TF-IDF to extract the top keywords from all documents\n",
        "vectorizer = TfidfVectorizer(max_features=10)  # Get top 10 keywords\n",
        "X = vectorizer.fit_transform(documents_str)\n",
        "\n",
        "# Get the top keywords\n",
        "keywords = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Display the top keywords across all documents\n",
        "print(\"Top 10 keywords across all documents:\")\n",
        "for keyword in keywords:\n",
        "    print(keyword)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCjrGtsvpzaA",
        "outputId": "cc00845f-33e4-4d6a-cb90-cfddf72a1b59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 keywords across all documents:\n",
            "clinical\n",
            "concepts\n",
            "context\n",
            "contextual\n",
            "data\n",
            "ipv\n",
            "medical\n",
            "model\n",
            "models\n",
            "patients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow the user to input a keyword\n",
        "user_keyword = input(\"Enter a keyword to search across the documents: \").lower()\n",
        "\n",
        "# Check if the entered keyword is in the top keywords\n",
        "if user_keyword in keywords:\n",
        "    print(f\"The keyword '{user_keyword}' is found in the documents.\")\n",
        "else:\n",
        "    print(f\"The keyword '{user_keyword}' is not found in the top keywords.\")\n",
        "\n",
        "# Calculate relevance scores for each document\n",
        "keyword_index = keywords.tolist().index(user_keyword) if user_keyword in keywords else None\n",
        "if keyword_index is not None:\n",
        "    relevance_scores = X[:, keyword_index].toarray().flatten()\n",
        "\n",
        "    # Pair the relevance scores with document indices\n",
        "    doc_scores = list(enumerate(relevance_scores))\n",
        "\n",
        "    # Sort documents by relevance score in descending order\n",
        "    sorted_docs = sorted(doc_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Show the top 5 documents relevant to the keyword\n",
        "    print(\"Top 5 documents relevant to the keyword:\")\n",
        "    for idx, score in sorted_docs[:5]:\n",
        "        print(f\"Document {idx + 1}: Relevance score = {score:.4f}\")\n",
        "        print(f\"Text: {documents[idx][:500]}...\")  # Show a preview of the document\n",
        "        print('-' * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dzRCtTMqLUQ",
        "outputId": "e97987a9-782d-48f6-a92b-963ac23f30be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a keyword to search across the documents: models\n",
            "The keyword 'models' is found in the documents.\n",
            "Top 5 documents relevant to the keyword:\n",
            "Document 1: Relevance score = 0.3925\n",
            "Text: Proceedings of Machine Learning Research N:1–17, 2020\n",
            "Machine Learning for Healthcare\n",
            "UPSTAGE: Unsupervised Context Augmentation for\n",
            "Utterance Classiﬁcation in Patient-Provider Communication\n",
            "Do June Min1, Veronica Perez-Rosas1, Shihchen Kuo2, William H. Herman2,\n",
            "Rada Mihalcea1\n",
            "dojmin@umich.edu, vrncapr@umich.edu, shihchk@med.umich.edu, wherman@med.umich.edu,\n",
            "mihalcea@umich.edu\n",
            "1Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor,\n",
            "MI, USA\n",
            "2Department of In...\n",
            "--------------------------------------------------------------------------------\n",
            "Document 2: Relevance score = 0.1240\n",
            "Text: Proceedings of Machine Learning Research 106:1–25, 2020\n",
            "Machine Learning for Healthcare\n",
            "Fast, Structured Clinical Documentation via Contextual\n",
            "Autocomplete\n",
            "Divya Gopinath\n",
            "divyagop@mit.edu\n",
            "Department of Electrical Engineering & Computer Science\n",
            "Massachusetts Institute of Technology\n",
            "Cambridge, MA, USA\n",
            "Monica Agrawal\n",
            "magrawal@mit.edu\n",
            "Department of Electrical Engineering & Computer Science\n",
            "Massachusetts Institute of Technology\n",
            "Cambridge, MA, USA\n",
            "Luke Murray\n",
            "lsmurray@mit.edu\n",
            "Department of Electrical ...\n",
            "--------------------------------------------------------------------------------\n",
            "Document 3: Relevance score = 0.1073\n",
            "Text: Intimate Partner Violence and Injury Prediction From Radiology Reports\n",
            "Irene Y. Chen1∗, Emily Alsentzer2, Hyesun Park3, Richard Thomas4, Babina Gosangi5,\n",
            "Rahul Gujrathi3, and Bharti Khurana3,6\n",
            "1Electrical Engineering and Computer Science, Massachusetts Institute of Technology,\n",
            "Cambridge, MA 02139, USA\n",
            "2Health Sciences and Technology, Massachusetts Institute of Technology,\n",
            "Cambridge, MA 02139, USA\n",
            "3Department of Radiology, Brigham and Women’s Hospital, Boston, MA 02115, USA\n",
            "4Department of Radiolo...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow the user to select a document to see the full text\n",
        "try:\n",
        "    doc_choice = int(input(\"Enter the document number to see the full text (1-3): \")) - 1\n",
        "\n",
        "    # Check if the document number is valid\n",
        "    if 0 <= doc_choice < len(documents):\n",
        "        print(f\"\\nFull text of Document {doc_choice + 1}:\\n\")\n",
        "        # Display a preview of the document (first 500 characters)\n",
        "        print(documents[doc_choice][:500])  # Show first 500 characters to avoid printing too much\n",
        "    else:\n",
        "        print(\"Invalid document number. Please enter a number between 1 and 3.\")\n",
        "except ValueError:\n",
        "    print(\"Invalid input. Please enter a valid integer.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCu7Ccj8qMyn",
        "outputId": "a1c59114-746e-4b19-a813-093f923cf54e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the document number to see the full text (1-3): 3\n",
            "\n",
            "Full text of Document 3:\n",
            "\n",
            "Intimate Partner Violence and Injury Prediction From Radiology Reports\n",
            "Irene Y. Chen1∗, Emily Alsentzer2, Hyesun Park3, Richard Thomas4, Babina Gosangi5,\n",
            "Rahul Gujrathi3, and Bharti Khurana3,6\n",
            "1Electrical Engineering and Computer Science, Massachusetts Institute of Technology,\n",
            "Cambridge, MA 02139, USA\n",
            "2Health Sciences and Technology, Massachusetts Institute of Technology,\n",
            "Cambridge, MA 02139, USA\n",
            "3Department of Radiology, Brigham and Women’s Hospital, Boston, MA 02115, USA\n",
            "4Department of Radiolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LD0zEBu8qQ4_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}